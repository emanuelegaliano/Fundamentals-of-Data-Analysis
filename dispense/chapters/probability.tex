\chapter{Probabilità nell'analisi dei dati}
Durante l'analisi dei dati, spesso ci si imbatte in situazioni in cui è necessario comprendere e quantificare l'incertezza associata ai dati raccolti. La probabilità fornisce un quadro teorico per affrontare queste situazioni, permettendo di fare inferenze basate su campioni di dati.

\section{Esperimenti casuali}
\subsection{Spazio degli eventi}
\begin{nicequote}
    Si definisce \textbf{spazio degli eventi} l'insieme di tutti i possibili risultati di un esperimento casuale:
    \[ \Omega = \{ \omega_1, \omega_2, \ldots, \omega_n \}
    \]
\end{nicequote}

\noindent
Dallo spazio degli eventi\footnote{Notare che lo spazio degli eventi è denominato dallo $\Omega$ come la popolazione (sotto-sezione \ref{subsec:popolazione}), non è un errore ma una convenzione (non sono la stessa cosa)}, possiamo dare una seconda definizione di \textbf{evento semplice}.
\begin{nicequote}
    Un \textbf{evento semplice} è un sottoinsieme dello spazio degli eventi che contiene un solo elemento:
    \[ A = \{ \omega_i \} \]
\end{nicequote}

\noindent
Un esempio di un evento semplice è l'estrazione di un asso da un mazzo di carte standard.

Molto spesso però, il risultato atteso è più grande di un singolo evento semplice. In questo caso, definiamo un \textbf{evento}.
\begin{nicequote}
    Un \textbf{evento} è un sottoinsieme dello spazio degli eventi che contiene più di un elemento:
    \[A = \{\omega_i, \omega_{j}, \ldots\} \subseteq \Omega\]
\end{nicequote}

\noindent
Spesso si denota \(\overline{A} = \Omega \setminus A\) per indicare l'evento complementare di \(A\). Da questa definizione possiamo trarre due semplici conclusioni: 
\begin{itemize}
    \item Lo spazio degli eventi \(\Omega\) è un evento, in quanto contiene tutti gli eventi semplici. In particolare viene chiamato \textbf{evento certo}, in quanto sempre vero.
    \item L'insieme vuoto \(\emptyset\) è un evento che non può mai avvenire, chiamato \textbf{evento impossibile}.
\end{itemize}

\section{Variabili Aleatorie}
\begin{nicequote}
    Una \textbf{variabile aleatoria} è una funzione che associa ad ogni evento semplice un numero reale:
    \[ X: \Omega \rightarrow E\]
    Dove $E$ è uno spazio misurabile.
\end{nicequote}

\section{Definizione dei dati}
\begin{nicequote}
    Nel contesto dell'analisi dei dati, i \textbf{dati} sono considerati come realizzazioni di variabili aleatorie. Ogni osservazione raccolta durante un esperimento casuale può essere vista come un'istanza di una variabile aleatoria.
\end{nicequote}

\section{Probabilità}
Poiché i risultati di una variabile aleatoria sono legati a eventi stocastici e non deterministici, è necessario definire una misura che quantifichi la probabilità di accadimento di tali eventi.
\begin{nicequote}
    Una \textbf{misura di probabilità} è una funzione \(P\) che assegna a ogni evento \(A \subseteq \Omega\) un numero reale compreso tra 0 e 1.
\end{nicequote}

\subsection{Assiomi}
La misura di probabilità, generalmente soddisfa alcuni assiomi:
\begin{itemize}
    \item \(P(\Omega) = 1\): La probabilità dell'evento certo è 1.
    \item \(P(\emptyset) = 0\): La probabilità dell'evento impossibile è 0.
    \item Se \(A_1, A_2, \ldots, A_n\) sono eventi mutuamente esclusivi, allora:
    \[ P\left(\bigcup_{i=1}^{n} A_i\right) = \sum_{i=1}^{n} P(A_i) \]
\end{itemize}

\subsection{Proprietà}
Dalle definizioni e dagli assiomi sopra riportati, possiamo derivare alcune proprietà utili della misura di probabilità:
\begin{itemize}
    \item \textbf{Complementarità}: \(P(\overline{A}) = 1 - P(A)\)
    \item \textbf{Monotonicità}: Se \(A \subseteq B\), allora \(P(A) \leq P(B)\)
    \item \textbf{Additività}: Per due eventi qualsiasi \(A\) e \(B\):
    \[ P(A \cup B) = P(A) + P(B) - P(A \cap B) \]
\end{itemize}

\subsection{Probabilità di Laplace}
In alcuni casi particolari, come negli esperimenti con esiti equiprobabili, possiamo utilizzare la definizione classica di probabilità proposta da Laplace.
\begin{nicequote}
    La \textbf{probabilità di Laplace} di un evento \(A\) è definita come il rapporto tra il numero di esiti favorevoli all'evento \(A\) e il numero totale di esiti possibili:
    \[ P(A) = \frac{\text{numero di esiti favorevoli ad } A}{\text{numero totale di esiti possibili}} \]
\end{nicequote}

\section{Stima di probabilità dalle osservazioni}
Nell'analisi dei dati, spesso non conosciamo la distribuzione di probabilità sottostante. In questi casi, possiamo stimare la probabilità di un evento basandoci sulle osservazioni raccolte.

\subsection{Approccio frequentista}
L'approccio frequentista stima la probabilità di un evento \(A\) come il rapporto tra il numero di volte in cui si verifica l'evento e il numero totale di osservazioni effettuate:
\[
P(A) \approx \frac{\text{numero di volte che si verifica } A}{\text{numero totale di osservazioni}}
\]

Il problema di questo approccio è che la stima può essere imprecisa se il numero di osservazioni è limitato o se l'evento è raro.

\subsection{Approccio bayesiano}
L'approccio bayesiano utilizza il teorema di Bayes per aggiornare la stima della probabilità di un evento \(A\).

\paragraph{Teorema di Bayes.} 
Siano \(A\) e \(B\) due eventi con \(P(B) > 0\). Allora la probabilità condizionata di \(A\) dato \(B\) è data da:
\[ P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)} \]
In questo contesto, \(P(A)\) rappresenta la probabilità a priori dell'evento \(A\), mentre \(P(A|B)\) è la probabilità a posteriori di \(A\) dopo aver osservato l'evento \(B\).

Questo approccio 'incorpora la probabilità a priori e aggiorna la stima in base alle nuove evidenze, risultando particolarmente utile in situazioni con dati limitati o in presenza di eventi rari. In questi contesti, infatti, vediamo la probabilità come una stima di \emph{incertezza} piuttosto che una frequenza oggettiva.

Un esempio può essere la diagnosi medica, dove la probabilità di una malattia può essere aggiornata in base ai sintomi osservati e ai risultati dei test diagnostici.

\section{Probabilità congiunta}
In molti casi, è utile considerare la probabilità di due o più eventi che si verificano simultaneamente. Questa è nota come \textbf{probabilità congiunta}.
\begin{nicequote}
    La \textbf{probabilità congiunta} di due eventi \(A\) e \(B\) è definita come la probabilità che entrambi gli eventi si verifichino.
\end{nicequote}

Un esempio comune è la probabilità che un paziente abbia sia la febbre che un'infezione batterica.

\textit{N.B.} La probabilità congiunta non è una probabilità condizionata.

\subsection{Regola della somma}
Un modo di calcolare la probabilità congiunta è attraverso le tabelle di contingenza, che mostrano la frequenza con cui si verificano combinazioni di eventi.

Un altro modo è sfruttare un approccio frequentista, contando le occorrenze congiunte degli eventi nei dati osservati.

Si fa questo considerando una tabella di contingenza, ovvero una tabella che riporta le frequenze con cui si verificano le combinazioni di due o più variabili categoriali. Ad esempio, supponiamo di avere due eventi \(A\) e \(B\) con due possibili esiti ciascuno (vero/falso). La tabella di contingenza potrebbe essere strutturata come segue:
\begin{table}[H]
\centering
\footnotesize
\setlength{\tabcolsep}{8pt}
\begin{tabular}{l*{4}{c}c}
	oprule
 & $Y=y_1$ & $Y=y_2$ & $\dots$ & $Y=y_l$ & Total \\
\midrule
$X=x_1$ & $n_{11}$ & $n_{12}$ & $\dots$ & $n_{1l}$ & $n_{1+}$ \\
$X=x_2$ & $n_{21}$ & $n_{22}$ & $\dots$ & $n_{2l}$ & $n_{2+}$ \\
$\vdots$ & $\vdots$ & $\vdots$ & $\ddots$ & $\vdots$ & $\vdots$ \\
$X=x_k$ & $n_{k1}$ & $n_{k2}$ & $\dots$ & $n_{kl}$ & $n_{k+}$ \\
\midrule
Total & $n_{+1}$ & $n_{+2}$ & $\dots$ & $n_{+l}$ & $n$ \\
\bottomrule
\end{tabular}
\caption{Esempio generale di tabella di contingenza}
\label{tab:contingency_example}
\end{table}

\noindent
Dove:
\begin{itemize}
    \item $n_{ij}$ rappresenta il numero di osservazioni in cui l'evento \(X=x_i\) e l'evento \(Y=y_j\) si verificano contemporaneamente.
    \item $n_{i+}$ è il totale delle osservazioni per l'evento \(X=x_i\).
    \item $n_{+j}$ è il totale delle osservazioni per l'evento \(Y=y_j\).
    \item $n$ è il numero totale di osservazioni.
\end{itemize}

Da questo, possiamo calcolare la probabilità congiunta \(P(X=x_i, Y=y_j)\) come:
\[
P(X=x_i, Y=y_j) = \frac{n_{ij}}{n}
\]

\begin{nicequote}
    Dalla tabella \ref{tab:contingency_example}, la probabilità marginale è definita come:
    \[ P(X=x_i) = \frac{n_{i+}}{n} \]
    \[ P(Y=y_j) = \frac{n_{+j}}{n} \]
\end{nicequote}

Da qui, possiamo definire la probabilità marginale di un evento \(X\) come la somma delle probabilità congiunte su tutti i possibili esiti dell'altro evento \(Y\):
\[
P(X=x_i) = \frac{n_{i+}}{n} = \frac{\sum_{j} n_{ij}}{n} = \sum_{j} \frac{n_{ij}}{n} = \sum_{j} P(X=x_i, Y=y_j)
\]

Questo risultato è conosciuto come \textbf{regola della somma}, che ci permette di calcolare la probabilità marginale di un evento sommando le probabilità congiunte con tutti gli esiti dell'altro evento (marginalizzazione).

\section{Probabilità condizionata}
In molte situazioni, è utile conoscere la probabilità di un evento dato che un altro evento si è verificato. Questa è nota come \textbf{probabilità condizionata}.
\begin{nicequote}
    La \textbf{probabilità condizionata} di un evento \(A\) dato che un evento \(B\) si è verificato è definita come:
    \[ P(X|Y) = \frac{P(X, Y)}{P(Y)} \]
\end{nicequote}

Possiamo utilizzare di nuovo la tabella di contingenza per calcolare la probabilità condizionata. Ad esempio, la probabilità condizionata di \(X=x_i\) dato \(Y=y_j\) è:
\[
P(X=x_i | Y=y_j) = \frac{\# \text{casi dove } X = x_i \text{ e } Y = y_j}{\# \text{casi dove } Y = y_j} = \frac{n_{ij}}{n} \cdot \frac{n}{n_{+j}} = \frac{n_{ij}}{n_{+j}} = \frac{P(X=x_i, Y=y_j)}{P(Y=y_j)}
\]

\textbf{N.B.} La probabilità condizionata è definita solo se \(P(Y) > 0\), anche perché non si può definire la probabilità di un evento dato che un evento impossibile si è verificato: sarebbe un controsenso.

\subsection{Regola del prodotto}
Un modo alternativo di calcolare la probabilità congiunta è attraverso la regola del prodotto, che sfrutta la probabilità condizionata.

Possiamo dire, che la probabilità condizionata è:
\[
P(X = x, Y = y) = \frac{P(X = x | Y = y)}{P(Y = y)}
\]

\noindent
Da qui segue:
\[
P(X = x, Y = y) = P(X = x | Y = y) \cdot P(Y = y)
\]

La probabilità del prodotto ci permette di calcolare la probabilità congiunta di due eventi moltiplicando la probabilità condizionata di uno degli eventi per la probabilità dell'altro evento.

\section{Regola della catena per le probabilità condizionate}
Quando si lavora con più variabili, la regola del prodotto può essere estesa per calcolare la probabilità condizionata di una variabile dato un insieme di altre variabili. Questa estensione è nota come \textbf{regola della catena}.

\noindent
Sapendo che:
\[
P(X, Y, Z) = P(X | Y, Z) \cdot P(Y, Z)
\]

\noindent
Possiamo espandere ulteriormente \(P(Y, Z)\) usando la regola del prodotto:
\[
P(Y, Z) = P(Y | Z) \cdot P(Z)
\]

\noindent
Sostituendo questa espressione nella precedente, otteniamo:
\[
P(X, Y, Z) = P(X | Y, Z) \cdot P(Y | Z) \cdot P(Z)
\]

\noindent
Questa è la regola della catena per tre variabili. In generale, per \(n\) variabili \(X_1, X_2, \ldots, X_n\), la regola della catena si estende come segue:
\[
P(X_1, X_2, \ldots, X_n) = P(X_1) \prod_{i=2}^n P(X_i | X_1, X_2, \ldots, X_{i-1})
\]

\section{Indipendenza}
Due variabili aleatorie \(X\) e \(Y\) sono dette \textbf{indipendenti} se la conoscenza del valore di una non fornisce alcuna informazione sul valore dell'altra. In termini di probabilità, questo si traduce nella seguente condizione:
\[
P(X | Y) = P(X) \cdot P(Y)
\]

\noindent
L'indipendenza si denota come:
\[
X \perp Y
\]

Se due variabili sono indipendenti, allora la probabilità condizionata di una variabile dato l'altra è semplicemente la probabilità marginale della prima variabile:
\[
P(X | Y) = \frac{P(X, Y)}{P(Y)} = \frac{P(X) \cdot P(Y)}{P(Y)} = P(X)
\]

\subsection{Indipendenza condizionata}
Due variabili aleatorie \(X\) e \(Y\) sono dette \text{indipendenti condizionalmente} rispetto a una terza variabile \(Z\) se, dato il valore di \(Z\), la conoscenza del valore di \(X\) non fornisce alcuna informazione sul valore di \(Y\), e viceversa. In termini di probabilità, questo si traduce nella seguente condizione:
\[
P(X, Y | Z) = P(X | Z) \cdot P(Y | Z)
\]

\noindent
E quindi, si può denotare come:
\[
X \perp Y | Z
\]