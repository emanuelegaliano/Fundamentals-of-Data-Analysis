\chapter{Distribuzione dei dati}
Il problema dei dati è che non sempre la singola probabilità di un evento è sufficiente a descrivere il fenomeno che stiamo studiando. Spesso infatti è necessario considerare l'insieme delle possibili occorrenze di un evento.

\section{Distribuzione di probabilità}
\begin{nicequote}
    La distribuzione di probabilità di una variabile casuale descrive come le probabilità sono distribuite tra i possibili valori che la variabile può assumere.
\end{nicequote}

Nel caso di variabili casuali discrete, la distribuzione di probabilità viene denominata \textbf{funzione di massa di probabilità} (pmf, \textit{probability mass function}), mentre nel caso di variabili casuali continue viene chiamata \textbf{funzione di densità di probabilità} (pdf, \textit{probability density function}).

Una distribuzione di probabilità caratterizza completamente una variabile casuale, in quanto fornisce tutte le informazioni necessarie per calcolare le probabilità di qualsiasi evento associato a quella variabile. Denotiamo con \(P(X)\) la distribuzione di probabilità della variabile casuale \(X\) e possiamo scrivere che \textbf{"$X$ segue la distribuzione $P(X)$"} come:
\[
X \sim P(X)
\]

\section{Distribuzioni discrete}
Una distribuzione di probabilità discreta è utilizzata per variabili casuali che possono assumere solo un numero finito o numerabile di valori.

\subsection{Funzione di massa di probabilità (PMF)}
 La \textbf{funzione di massa di probabilità} (PMF) è la funzione che descrive la probabilità di ciascun valore possibile.

Una PMF sulla variabile casuale $X$ è definita come:
\[
P: \Omega \rightarrow [0, 1]
\]
La PMF deve soddisfare una proprietà:
\[
\sum_{x \in \Omega} P(x) = 1
\]

Ipotizzando di simulare il lancio di un dado a sei facce, la PMF associata a questo esperimento è:
\[
P(X = x) = \begin{cases}
\frac{1}{6} & \text{se } x \in \{1, 2, 3, 4, 5, 6\} \\
0 & \text{altrimenti}
\end{cases}
\]

Questo significa che ogni faccia del dado ha una probabilità di $\frac{1}{6}$ di essere estratta, e la somma delle probabilità di tutte le facce è uguale a 1, come richiesto dalla proprietà della PMF.

\subsection{Funzione di distribuzione cumulativa (CDF)}
Se consideriamo il caso dove la variabile casuale $X$ può essere ordinata (come nel caso dei numeri interi), possiamo definire la \textbf{funzione di distribuzione cumulativa} (CDF, \textit{cumulative distribution function}) come:
\[
F(x) = P(X \leq x) = \sum_{y \leq x} P(X = y)
\]

La CDF fornisce la probabilità cumulativa che la variabile casuale $X$ assuma un valore minore o uguale a $x$ (per esempio, tutte le persone con altezza minore o uguale a 170 cm).

\section{Distribuzioni continue}
Una distribuzione di probabilità continua è utilizzata per variabili casuali che possono assumere un infinito numero di valori all'interno di un intervallo. Tuttavia, per poter capire il concetto di distribuzione continua, bisogna prima introdurre il concetto di funzione di densità di probabilità (PDF).

\subsection{Funzione di densità di probabilità (PDF)}\label{subsec:pdf}
La \textbf{funzione di densità di probabilità} (PDF) è la funzione che descrive la densità di probabilità in ogni punto dell'intervallo. Una PDF sulla variabile casuale $X$ è definita come:
\[
f: \Omega \rightarrow [0, 1]
\]

\noindent
E deve soddisfare la seguente proprietà:
\[
\int f(x) \, dx = 1
\]

\noindent
\textit{(Questa condizione è equivalente alla somma delle probabilità nella distribuzione discreta).}

Si può utilizzare la PDF per calcolare la probabilità che la variabile casuale $X$ assuma un valore all'interno di un intervallo specifico $[a, b]$:
\[
P(a \leq X \leq b) = \int_{a}^{b} f(x) \, dx
\]

La pdf descrive la densità di probabilità in ogni punto, ma non fornisce direttamente la probabilità di un singolo punto, poiché in una distribuzione continua la probabilità di un singolo punto è sempre zero: si parla infatti di densità di probabilità e non di probabilità puntuale. Tanto è più grande il valore della pdf in un punto, tanto più alta è la probabilità che la variabile casuale assuma valori vicini a quel punto.

\paragraph{PDF uniforme.} Un esempio di PDF è la distribuzione uniforme continua su un intervallo $[a, b]$, dove la PDF è definita come:
\[
f(x) = \begin{cases}
\frac{1}{b - a} & \text{se } a \leq x \leq b \\
0 & \text{altrimenti}
\end{cases}
\]

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{images/uniform_pdf.png}
    \caption{Esempio di PDF uniforme continua su un intervallo $[a, b]$. La funzione è costante all'interno dell'intervallo e zero al di fuori.}
    \label{fig:uniform_pdf}
\end{figure}

\paragraph{Approssimare la PDF con istogrammi.} In pratica, quando si lavora con dati continui, spesso si cerca di approssimare la PDF utilizzando istogrammi (sezione \ref{sec:istogramma}).

Per un certo bin $b_j$ sia $h_j$ l'altezza dell'istogramma e sia $w_j$ la larghezza del bin. Allora possiamo dire, per un istogramma normalizzato\footnote{Un istogramma è detto normalizzato quando l'area totale sotto l'istogramma è pari a 1. Ovviamente non soddisfano i requisiti di una PDF, ma possono comunque fornire un'approssimazione utile.}, che l'altezza del bin è:
\[
h_j = \frac{c_j}{n}
\]
dove $c_j$ è il conteggio degli elementi nel bin $b_j$ e $n$ è il numero totale di elementi.

\noindent
Da questo, possiamo approssimare l'area dell'istogramma nel bin $b_j$ come:
\[
A_j = h_j \cdot w_j = \frac{c_j}{n} \cdot w_j
\]

Calcolata quest'area per un $j$-esimo bin, possiamo calcolare l'area dell'istogramma per intero come:
\[
\int_{-\infty}^{\infty} H(X) \, dx = \sum_{j} A_j = \sum_{j} \frac{c_j}{n} \cdot w_j = \sum_{j} w_j \neq 1
\]

Per soddisfare la proprietà di una PDF, dobbiamo normalizzare l'istogramma in modo che l'area totale sia pari a 1. Per fare ciò, possiamo dividere l'altezza di ogni bin per l'area totale dell'istogramma:
\[
h'_j = \frac{c_j}{n \cdot \sum_{j} w_j}
\]

\noindent
e da qui riscrivere l'area del bin normalizzato come:
\[
\int_{-\infty}^{\infty} H'(X) \, dx = \sum_{j} A'_j = \sum_{j} h'_j \cdot w_j = \sum_{j} \frac{c_j}{n \cdot \sum_{j} w_j} \cdot w_j = 1
\]

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{images/histogram_pdf_comparison.png}
    \caption{Confronto tra due rappresentazioni dell'istogramma delle età dei passeggeri. 
    A sinistra: istogramma normalizzato, in cui l'altezza di ciascun bin è pari alla frequenza relativa (la somma delle altezze dei bin è 1); l'asse $y$ è interpretato come probabilità. 
    A destra: istogramma di densità, in cui l'area totale sotto le barre è 1 e quindi le altezze approssimano la funzione di densità di probabilità continua. In rosso è mostrata la PDF normale stimata sui dati.}
    \label{fig:histogram_pdf_comparison}
\end{figure}

\subsection{Funzione di distribuzione cumulativa (CDF)}
Ricordando che la CDF è definita come la probabilità cumulativa che la variabile casuale $X$ assuma un valore minore o uguale a $x$, possiamo estendere questa definizione anche alle distribuzioni continue:
\[
F(x) = P(X \leq x)
\]

La CDF fornisce la probabilità cumulativa che la variabile casuale $X$ assuma un valore minore o uguale a $x$. In una distribuzione continua, la CDF è ottenuta integrando la PDF:
\[
F(x) = \int_{-\infty}^x f(t) \, dt
\]

\noindent
Dove $f(t)$ è la PDF della variabile casuale $X$.

Possiamo trarre diverse conclusioni da qui:
\begin{itemize}
    \item La CDF è una funzione non decrescente, poiché le probabilità cumulative non possono diminuire al crescere di $x$.
    \item Conoscendo la CDF, possiamo ottenere la PDF derivando la CDF:
    \[
    f(x) = \frac{d}{dx} F(x)
    \]
    \item La CDF di una distribuzione continua è continua, a differenza della CDF di una distribuzione discreta che può presentare salti. 
\end{itemize}

\section{Distribuzioni di probabilità comuni}
Ci sono diverse distribuzioni di probabilità comuni che vengono spesso utilizzate in statistica e machine learning. Molto spesso si utilizzano perché si nota che la distribuzione che stiamo studiando si avvicina a una di queste distribuzioni standard e in quel caso si possono sfruttare le loro proprietà per fare inferenza statistica.

\subsection{Distribuzione uniforme discreta}
La distribuzione uniforme discreta è una distribuzione di probabilità in cui tutti i valori possibili di una variabile casuale discreta hanno la stessa probabilità di verificarsi al variare di un parametro $k$:
\[
P(X = a_i) = \frac{1}{k}
\]

\noindent
Dove $\Omega = \{a_1, ..., a_k\}$.

\subsection{Distribuzione di Bernoulli}
La distribuzione di Bernoulli è una distribuzione di probabilità discreta che descrive un esperimento con due possibili esiti: successo e fallimento. La distribuzione viene definito come un singolo parametro $\phi$, che rappresenta la probabilità di successo. Quindi possiamo formulare la distribuzione di Bernoulli come:
\[
P(X = x) = \begin{cases}
\phi & \text{se } x = 1 \\
1 - \phi & \text{se } x = 0
\end{cases}
\]

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{images/bernoulli_distribution.png}
    \caption{Esempio di distribuzione di Bernoulli su una moneta truccata con parametro $\phi = 0.6$. La probabilità di successo (ovvero fare testa) è 0.6, mentre la probabilità di fallimento (fare croce) è 0.4}
    \label{fig:bernoulli_distribution}
\end{figure}

\subsection{Distribuzione binomiale}
La distribuzione binomiale è una distribuzione di probabilità discreta (PMF) su numeri naturali con parametri $n$ e $p$. Essa modella la probabilità di ottenere $k$ successi in una sequenza di $n$ esperimenti indipendenti che seguono una distribuzione di Bernoulli con parametro $p$.

\noindent
La funzione di massa di probabilità è data da:
\[
P(k) = \binom{n}{k} p^{k} (1 - p)^{n-k}
\]

\noindent
Dove:
\begin{itemize}
    \item $k$ è il numero di successi
    \item $n$ è il numero di prove indipendenti
    \item $p$ è la probabilità di successo in una singola prova
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{images/binomial_distribution.png}
    \caption{Funzioni di massa di probabilità (PMF) della distribuzione binomiale per diversi valori di $n$ (numero di prove) e $p$ (probabilità di successo in ciascuna prova). Ogni curva mostra la probabilità di ottenere $k$ successi su $n$ prove indipendenti: si osserva che il picco della distribuzione si sposta attorno al valore atteso $np$ e che, al crescere di $n$, la distribuzione tende a diventare più concentrata e più simile a una forma "gaussiana".}
    \label{fig:binomial_distribution}
\end{figure}

\paragraph{Lancio di una moneta.}
Un esempio comune di distribuzione binomiale è il lancio di una moneta più volte, dove si vuole calcolare la probabilità di ottenere un certo numero di teste (successi) in un numero totale di lanci (prove):
\[
P(k) = \binom{n}{k} \left(\frac{1}{2}\right)^{k} \left(1 - \frac{1}{2}\right)^{n-k} = \binom{n}{k} \left(\frac{1}{2}\right)^{n}
\]

\noindent
Dove $n$ è il numero totale di lanci e $k$ è il numero di teste ottenute. Se prendessimo $n=3$ numero di lanci, $k=3$ numero di successi (teste) e $p=0.5$ probabilità di successo in ogni lancio, avremmo:
\[
P(3) = \binom{3}{3} (0.5)^{3} (1 - 0.5)^{3-3} = 1 \cdot (0.5)^{3} \cdot 1 = 0.125
\]

\subsection{Distribuzione categorica}
La distribuzione categorica è una generalizzazione della distribuzione di Bernoulli per variabili casuali che possono assumere $k$ categorie distinto per un certo $k$ finito.

La distribuzione categorica è definita da un vettore di probabilità $\boldsymbol{p} \in [0, 1]^k$, dove ogni $p_i$ ci dà la probabilità di essere nell'$i$-esima categoria, e deve soddisfare la condizione:
\[
\sum_{i=1}^{k} p_i = 1
\]

La forma analitica è data da:
\[
P(x = i) = p_i \quad \text{per } i = 1, 2, \ldots, k
\]

\paragraph{Esempio: lancio di un dado truccato.}
Consideriamo un singolo lancio di un dado a sei facce truccato. Gli esiti possibili sono:
\[ X \in \{1,2,3,4,5,6\}. \]

\noindent
Se il dado è truccato in modo che le probabilità siano:
\begin{itemize}
    \item $P(X = 1) = 0.10$
    \item $P(X = 2) = 0.15$
    \item $P(X = 3) = 0.20$
    \item $P(X = 4) = 0.20$
    \item $P(X = 5) = 0.10$
    \item $P(X = 6) = 0.25$
\end{itemize}

Allora l'esito segue una distribuzione categorica con $k = 6$ e probabilità specificate $\{p_1, p_2, \dots, p_6\} = \{0.1,\,0.15,\,0.2,\,0.2,\,0.1,\,0.25\}$.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{images/categorical_distribution.png}
    \caption{Esempio di distribuzione categorica per il lancio di un dado truccato. Le altezze delle barre rappresentano le probabilità associate a ciascuna faccia del dado.}
    \label{fig:categorical_distribution}
\end{figure}

\subsection{Distribuzione multinomiale}
La distribuzione multinomiale è una generalizzazione della distribuzione binomiale per esperimenti con più di due possibili esiti. Viene utilizzata per modellare il numero di occorrenze di ciascuna categoria in una serie di prove indipendenti. In particolare, la distribuzione multinomiale descrive la probabilità di ottenere esattamente \( (n_1, \ldots, n_k) \) occorrenze per ciascuna delle $k$ categorie in una sequenza di $n$ espertimenti indipendenti che seguono una distribuzione categorica con probabilità \( (p_1, \ldots, p_k) \).

\noindent
Possiamo definire i parametri della distribuzione multinomiale come:
\begin{itemize}
    \item $n$: numero totale di prove indipendenti
    \item $k$: numero di categorie
    \item $p_i$: probabilità di successo per la categoria $i$ (con $i = 1, 2, \ldots, k$)\footnote{La somma totale di ogni $p_i$ deve fare 1.}
\end{itemize}

\noindent
Da questo, la funzione di massa di probabilità (PMF) della distribuzione multinomiale è data da:
\[
P(n_1, n_2, \ldots, n_k) = \frac{n!}{n_1! n_2! \ldots n_k!} p_1^{n_1} p_2^{n_2} \ldots p_k^{n_k}
\]

\paragraph{Lancio di un dado più volte.}
Un esempio comune di distribuzione multinomiale è il lancio di un dado più volte, dove si vuole calcolare la probabilità di ottenere un certo numero di occorrenze per ciascuna faccia del dado in un numero totale di lanci. Considerato un dado a sei facce, qual è la probabilità di ottenere:
\begin{itemize}
    \item 3 volte il numero 1, $n_1 = 3$
    \item 2 volte il numero 2, $n_2 = 2$
    \item 4 volte il numero 3, $n_3 = 4$
    \item 5 volte il numero 4, $n_4 = 5$
    \item 0 volte il numero 5, $n_5 = 0$
    \item 1 volta il numero 6, $n_6 = 1$
\end{itemize} 

\noindent
Sapendo che la probabilità di ottenere ciascuna faccia del dado è $p_i = \frac{1}{6}$ per ogni $i = 1, 2, \ldots, 6$. Abbiamo $k = 6$ categorie e $n = 15$ lanci, quindi possiamo calcolare la probabilità come:
\[
P(3, 2, 4, 5, 0, 1) = \frac{15!}{3! 2! 4! 5! 0! 1!} \left(\frac{1}{6}\right)^{3} \left(\frac{1}{6}\right)^{2} \left(\frac{1}{6}\right)^{4} \left(\frac{1}{6}\right)^{5} \left(\frac{1}{6}\right)^{0} \left(\frac{1}{6}\right)^{1} = 8.04 \times 10^{-5}
\]

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{images/multinomial_distribution.png}
    \caption{Esempio di distribuzione multinomiale per il lancio di un dado a sei facce 15 volte. Le altezze delle barre rappresentano le probabilità associate a ciascuna combinazione di occorrenze delle facce del dado.}
    \label{fig:multinomial_distribution}
\end{figure}

\subsection{Distribuzione Gaussiana (Normale)}
La distribuzione Gaussiana, o distribuzione normale, è una delle distribuzioni di probabilità più importanti e ampiamente utilizzate in statistica e machine learning. È molto importante perché, è una funzione di densità molto comune che descrive molti fenomeni naturali e processi casuali.

\noindent
La distribuzione Gaussiana è caratterizzata da due parametri principali:
\begin{itemize}
    \item La media \(\mu \in \mathbb{R}\) che rappresenta il centro della distribuzione.
    \item La deviazione standard \(\sigma > 0\) che misura la dispersione dei dati intorno alla media.
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{images/gaussian_distribution.png}
    \caption{Esempio di distribuzione Gaussiana (Normale) con media \(\mu = 0\) e deviazione standard \(\sigma = 1\). La curva a campana rappresenta la funzione di densità di probabilità (PDF) della distribuzione.}
    \label{fig:gaussian_distribution}
\end{figure}

\noindent
La formula analitica della distribuzione normale è data da:
\[
N(x, \mu, \sigma) = \sqrt{\frac{1}{2 \pi \sigma^2}} \; e^{-\frac{(x - \mu)^2}{2 \sigma^2}}
\]

Questa è la \textbf{funzione di densità di probabilità} (PDF) della normale. Ogni pezzo della formula ha un significato preciso:

\begin{itemize}
    \item Il termine \(\mu\) è la media. Controlla \textit{dove} è centrata la campana: il punto in cui la curva raggiunge il valore massimo è proprio \(x = \mu\). Spostare \(\mu\) verso destra o verso sinistra sposta tutta la distribuzione senza cambiarne la forma.
    \item Il termine \(\sigma\) è la deviazione standard. Controlla \textit{quanto è larga} o \textit{stretta} la campana. Se \(\sigma\) è piccolo, la distribuzione è molto concentrata attorno alla media (picco alto e stretto). Se \(\sigma\) è grande, la distribuzione è più sparsa (curva più bassa e larga). La varianza della distribuzione è \(\sigma^2\).
    \item Il fattore \(\frac{1}{\sigma \sqrt{2 \pi}}\), è un fattore di normalizzazione. Serve a garantire che l'area totale sotto la curva valga 1, cioè che la funzione sia davvero una densità di probabilità valida:
    \[
    \int_{-\infty}^{+\infty} N(x,\mu,\sigma)\,dx = 1.
    \]
    Senza questo termine la forma sarebbe "a campana", ma non rappresenterebbe una distribuzione di probabilità corretta.
    \item Il termine esponenziale \(e^{-\frac{(x - \mu)^2}{2\sigma^2}}\) determina la forma a campana. Il numeratore \((x-\mu)^2\) misura quanto \(x\) è lontano dalla media: più \(x\) è lontano, più questo quadrato cresce, e quindi più l'esponenziale crolla verso 0. Il denominatore \(2\sigma^2\) controlla quanto velocemente crolla: con una \(\sigma\) grande, si scende più lentamente (code più larghe); con una \(\sigma\) piccola, si scende molto in fretta.
\end{itemize}

\noindent
Possiamo notare una cosa molto interessante della distribuzione normale: calcolando l'intervallo di valori che si trovano entro una certa distanza dalla media, possiamo osservare che:
\begin{itemize}
    \item Circa il 68\% dei valori si trova entro una deviazione standard dalla media \((\mu - \sigma, \mu + \sigma)\).
    \item Circa il 95\% dei valori si trova entro due deviazioni standard dalla media \((\mu - 2\sigma, \mu + 2\sigma)\).
    \item Circa il 99.7\% dei valori si trova entro tre deviazioni standard dalla media \((\mu - 3\sigma, \mu + 3\sigma)\).
\end{itemize}

Questa cosa è utile per notare che, se una certa distribuzione segue la normale, allora possiamo fare delle stime sulla probabilità che un certo valore cada entro un certo intervallo dalla media. In pratica, la PDF ci dice quanto è "densa" la probabilità attorno a ciascun punto \(x\), mentre l'area sotto la curva tra due punti \(a\) e \(b\) ci dice la probabilità che la variabile aleatoria cada proprio tra \(a\) e \(b\). Questo è esattamente ciò che rende la normale così comoda per stimare intervalli di confidenza, fare assunzioni sui dati e modellare rumore nei modelli di machine learning.

\subsection{Teorema del limite centrale}\label{sec:clt}
Il teorema del limite centrale è uno dei risultati più importanti in statistica. 
\begin{nicequote}
    Il teorema del limite centrale afferma che la distribuzione della somma (o della media) di un gran numero di variabili casuali $\{ X_i \}_{i=1}^n$ indipendenti e identicamente distribuite tende a una distribuzione normale per \(n \rightarrow \infty\), indipendentemente dalla distribuzione originale delle variabili casuali $X_i$.
\label{quote:clt}
\end{nicequote}

Questo risultato è fondamentale perché giustifica la diffusione della distribuzione normale in molti contesti statistici e applicazioni pratiche. In particolare, il teorema del limite centrale consente di utilizzare la distribuzione normale come approssimazione per la distribuzione di campioni di grandi dimensioni, anche quando la distribuzione originale non è normale.

\paragraph{Esempio.}
Consideriamo un dado equo a sei facce, in cui ogni faccia da 1 a 6 ha la stessa probabilità \( \frac{1}{6} \).
Se lanciamo il dado una sola volta, il risultato è chiaramente discreto (1, 2, 3, 4, 5 o 6) e la distribuzione non assomiglia affatto a una Gaussiana.

Adesso però facciamo così: lanciamo il dado \(n\) volte, calcoliamo la \emph{media} dei risultati ottenuti, e ripetiamo questo esperimento molte volte.
Per \(n = 1\) le medie possibili coincidono con i valori del dado, quindi la distribuzione è piatta e discreta.
Per \(n = 2,5,10\) la distribuzione delle medie campionarie comincia a diventare più "a campana".
Per \(n = 50\) e soprattutto \(n = 5000\), le medie campionarie si concentrano attorno a circa \(3.5\) (che è il valore atteso di un dado equo) e la loro distribuzione è ormai molto simile a una distribuzione normale.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{images/ctl_diice_example.png}
    \caption{Esempio del teorema del limite centrale con il lancio di un dado equo. La distribuzione delle medie campionarie tende a una distribuzione normale.}
    \label{fig:central_limit_theorem}
\end{figure}

\subsection{Distribuzione Gaussiana Multivariata}
La distribuzione Gaussiana multivariata è un'estensione della distribuzione normale a più dimensioni. Viene utilizzata per modellare vettori di variabili casuali continue che possono essere correlate tra loro. La distribuzione è caratterizzata da due parametri principali:
\begin{itemize}
    \item Il vettore di medie \(\boldsymbol{\mu} \in \mathbb{R}^d\), che rappresenta il centro della distribuzione.
    \item La matrice di covarianza \(\boldsymbol{\Sigma} \in \mathbb{R}^{d \times d}\), che misura la dispersione e la correlazione tra le variabili.
\end{itemize}

\noindent
La formulazione analitica della distribuzione Gaussiana multivariata è data da:
\[
N(\boldsymbol{x}, \boldsymbol{\mu}, \boldsymbol{\Sigma}) =\sqrt{\frac{1}{(2 \pi)^d |\boldsymbol{\Sigma}|}} e^{-\frac{1}{2} (\boldsymbol{x} - \boldsymbol{\mu})^T \boldsymbol{\Sigma}^{-1} (\boldsymbol{x} - \boldsymbol{\mu})}
\]

\begin{figure}[H]
    \centering
    % Colonna di testo
    \begin{minipage}[t]{0.46\textwidth}
        \vspace{0pt} % forza l'allineamento in alto
        A due dimensioni, ovviamente, il vettore $\mu$ rappresenta il centro della distribuzione
        nel piano XY, mentre la matrice di covarianza $\Sigma$ determina la forma e
        l'orientamento delle ellissi di densità di probabilità.

        Spesso è difficile visualizzare la gaussiana multivariata in un grafico 3D,
        ma possiamo rappresentarla tramite curve di livello (linee di uguale densità)
        che mostrano come la densità di probabilità varia nello spazio bidimensionale.

        Come si può notare nella figura \ref{fig:multivariate_gaussian}, la distribuzione
        Gaussiana multivariata con media \((0,0)\) e correlazione positiva tra le due variabili
        mostra un picco al centro (la media) e le linee di livello formano ellissi orientate,
        indicando sia la varianza lungo le direzioni principali sia la dipendenza lineare
        tra le due componenti.

        Sotto la superficie 3D, le curve di livello rappresentano le linee di uguale densità sul piano XY. L'orientamento e la forma di queste ellissi sono determinate dalla matrice di covarianza \(\boldsymbol{\Sigma}\).
    \end{minipage}
    \hfill
    % Colonna con l'immagine
    \begin{minipage}[t]{0.47\textwidth}
        \vspace{0pt} % forza l'allineamento in alto
        \centering
        \includegraphics[width=\linewidth]{images/multivariate_normal.png}
    \end{minipage}

    \caption{Distribuzione Gaussiana bivariata con media \((0,0)\).
    La superficie 3D mostra la densità congiunta, mentre le curve di livello (ellissi)
    mostrano linee di uguale densità sul piano $XY$. L'orientamento delle ellissi è determinato
    dalla matrice di covarianza $\Sigma$.}
    \label{fig:multivariate_gaussian}
\end{figure}


\paragraph{Effetti di $\Sigma$.}
In una distribuzione normale a singola dimensione, l'effetto della dispersione è controllato dalla deviazione standard \(\sigma\). Nella distribuzione Gaussiana multivariata, la matrice di covarianza \(\boldsymbol{\Sigma}\) svolge un ruolo simile, ma in modo più complesso, in quanto determina \textbf{forma, orientamento e scala} della distribuzione nello spazio multidimensionale:
\begin{itemize}
    \item Quando $\Sigma$ è una matrice diagonale\footnote{Una matrice diagonale è una matrice quadrata in cui tutti gli elementi al di fuori della diagonale principale sono zero.}, le variabili sono indipendenti tra loro (in quanto $\sigma_{xy} = \sigma_{yx} = 0$), e la distribuzione appare come un "ellissoide" allineato con gli assi.
    \item Se la varianza lungo le assi è diversa (cioè gli elementi diagonali di $\Sigma$ sono diversi), la distribuzione sarà più "allungata" in alcune direzioni rispetto ad altre.
    \item Gli elementi fuori diagonale di $\Sigma$ rappresentano la covarianza tra le variabili. Se questi valori sono positivi, indica una correlazione positiva (le variabili tendono a crescere insieme); se sono negativi, indica una correlazione negativa (una variabile tende a crescere mentre l'altra diminuisce). Questo si riflette nell'orientamento delle ellissi di densità di probabilità.
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{images/multivariate_sigma_effects.png}
    \caption{Effetto della matrice di covarianza $\Sigma$ sulla distribuzione Gaussiana bivariata con media \((0,0)\). Ogni pannello mostra le curve di livello (isodensità), che evidenziano forma, orientamento e scala della distribuzione. Nella riga superiore: caso isotropico (varianze uguali su $X$ e $Y$), poi varianza di $X$ maggiore di quella di $Y$, poi varianza di $Y$ maggiore di quella di $X$; in questi casi $\Sigma$ è diagonale, quindi non c'è covarianza e le ellissi sono allineate con gli assi. Nella riga inferiore: presenza di termini fuori diagonale in $\Sigma$ (covarianza non nulla), che introduce correlazione tra le variabili. Con correlazione positiva le ellissi ruotano lungo la diagonale crescente, con correlazione negativa lungo la diagonale decrescente. Questo mostra che $\Sigma$ controlla non solo quanto è larga la distribuzione in ciascuna direzione, ma anche come è orientata nello spazio.}
    \label{fig:multivariate_sigma_effects}
\end{figure}

\paragraph{Stime dei parametri nella distribuzione Gaussiana multivariata.}
Per stimare i parametri della distribuzione Gaussiana multivariata, ovvero il vettore di medie \(\boldsymbol{\mu}\) e la matrice di covarianza \(\boldsymbol{\Sigma}\) possono essere ottenuti grazie alla massima verosimiglianza (MLE, \textit{maximum likelihood estimation}) sui dati osservati. 

\noindent
Nel caso \textbf{univariato}:
\begin{itemize}
    \item La stima della media \(\mu\) è data dalla media campionaria:
    \[
    \hat{\mu} = \frac{1}{n} \sum_{i=1}^{n} x_i
    \]
    \item La stima della varianza \(\sigma^2\) è data dalla varianza campionaria:
    \[
    \hat{\sigma}^2 = \frac{1}{n} \sum_{i=1}^{n} (x_i - \hat{\mu})^2
    \]
\end{itemize}

\noindent
Dove \(x_i\) sono i dati osservati e \(n\) è il numero totale di osservazioni.

\noindent
Nel caso \textbf{multivariato}:
\begin{itemize}
    \item La stima del vettore di medie \(\boldsymbol{\mu}\) è data dalla media campionaria vettoriale:
    \[
    \hat{\boldsymbol{\mu}} = \frac{1}{n} \sum_{i=1}^{n} \boldsymbol{x}_i
    \]
    \item La stima della matrice di covarianza \(\boldsymbol{\Sigma}\) è data dalla matrice di covarianza in relazione alla variabile casuale $X$:
    \[
    \hat{\boldsymbol{\Sigma}} = Cov(X) \Rightarrow \hat{\boldsymbol{\Sigma}}_{ij} = Cov(X_i, X_j)
    \]
\end{itemize}

\section{Descrivere una distribuzione di probabilità}
Esistono diverse misure per descrivere una distribuzione di probabilità, che si basano su concetti statistici come la media, la varianza e la forma della distribuzione stessa.

\subsection{Aspettativa (media)}
L'aspettativa, o valore atteso, di una variabile casuale \(X\) è una misura della tendenza centrale della distribuzione di probabilità. É simile alla media aritmetica, perché quando computiamo una media non facciamo altro che sommare tutti i valori di un insieme e dividere per il numero totale di valori. L'aspettativa fa la stessa cosa, ma tiene conto delle probabilità associate a ciascun valore.

In particolare, possiamo definire per una variabile casuale discreta l'aspettativa come se fosse una media pesata:
\[
E[X]_{X \sim P} = \sum_{x \in \Omega} x \cdot P(x)
\]

Nel caso di variabili continue, l'aspettativa è definita come:
\[
E[X]_{X \sim P} = \int_{x \in \Omega} x \cdot f(x) \, dx
\]
Dove \(f(x)\) è la funzione di densità di probabilità (PDF) della variabile casuale \(X\).

\subsection{Varianza e deviazione standard}
La varianza è una misura della dispersione dei valori di una variabile casuale rispetto alla sua media. Indica quanto i valori si discostano in media dall'aspettativa. La varianza di una variabile casuale \(X\) è definita come:
\[
Var_{X \sim P}[X] = E\left[(X - E_{X \sim P}[X])^2\right]
\]

Si utilizza spesso, però, la deviazione standard, che è la radice quadrata della varianza in quanto è più interpretabile:
\[
\sigma = \sqrt{Var_{X \sim P}[X]}
\]

\subsection{Covarianza}
La covarianza è una misura della relazione lineare tra due variabili casuali \(X\) e \(Y\). Indica come le due variabili variano insieme. La covarianza è definita come:
\[
Cov_{X \sim P_X, Y \sim P_Y}[X, Y] = E\left[(X - E_{X \sim P_X}[X]) (Y - E_{Y \sim P_Y}[Y])\right]
\]

\noindent
Si possono distinguere i termini:
\begin{itemize}
    \item $E[X], E[Y]$ sono le aspettative (medie) delle variabili casuali \(X\) e \(Y\).
    \item $(X - E_{X \sim P_X}[X])$ e $(Y - E_{Y \sim P_Y}[Y])$ sono le deviazioni delle variabili casuali \(X\) e \(Y\) rispetto alle loro aspettative.
    \item $(X-E[X])(Y-E[Y])$ rappresenta il prodotto delle deviazioni, che indica come le due variabili variano insieme.
\end{itemize}

\noindent
Possiamo distinguere tre casi:
\begin{itemize}
    \item Se la covarianza è positiva, significa che quando una variabile aumenta, l'altra tende ad aumentare anch'essa.
    \item Se la covarianza è negativa, significa che quando una variabile aumenta, l'altra tende a diminuire.
    \item Tanto la covarianza è vicina a zero, tanto meno le due variabili sono correlate linearmente.
\end{itemize}

Se $X$ è una variabile multidimensionale con $d$ componenti, la covarianza può essere rappresentata come una matrice di covarianza $\Sigma \in \mathbb{R}^{d \times d}$, dove ogni elemento $\Sigma_{ij}$ rappresenta la covarianza tra la $i$-esima e la $j$-esima componente di $X$:
\[
\Sigma_{ij} = Cov[X_i, X_j]
\]

\subsection{Entropia}
L'entropia è una misura della quantità di incertezza o imprevedibilità associata a una distribuzione di probabilità. In altre parole, l'entropia quantifica quanto "disordinata" o "casuale" è una variabile casuale.

\paragraph{Self-information.}
Prima di definire l'entropia, è utile introdurre il concetto di \textbf{self-information} (o informazione auto-riferita) di un evento \(x\), che misura la quantità di informazione associata al verificarsi di quell'evento. La self-information è definita come:
\[
I(x) = -\log P(x)
\]

\noindent
Il logaritmo viene solitamente calcolato in base 2 (bit) o in base \(e\) (nat).

Questa definizione ha senso perché eventi con bassa probabilità (cioè eventi rari) forniscono più informazione quando si verificano, mentre eventi con alta probabilità (eventi comuni) forniscono meno informazione. Possiamo anche notare che:
\begin{itemize}
    \item Il logaritmo rende la self-information additiva per eventi indipendenti. Se due eventi \(x\) e \(y\) sono indipendenti, allora:
    \[
    I(X = x, Y = y) = -\log[P(X = x) \cdot P(Y = y)] = I(x) + I(y)
    \]
    \item Inoltre il logaritmo negativo riflette il fatto che eventi più probabili (con \(P(x)\) vicino a 1) hanno self-information più bassa, mentre eventi meno probabili (con \(P(x)\) vicino a 0) hanno self-information più alta.
\end{itemize}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.7\textwidth]{images/self_information.png}
    \caption{Esempio di self-information \(I(x) = -\log P(x)\) per diversi valori di probabilità \(P(x)\). Si nota che eventi con bassa probabilità (vicino a 0) hanno alta self-information, mentre eventi con alta probabilità (vicino a 1) hanno bassa self-information.}
    \label{fig:self_information}
\end{figure}

\paragraph{Entropia di una distribuzione.}
Per una certa variabile casuale \(X\) con distribuzione di probabilità \(P(X)\), l'entropia \(H(X)\) è definita come l'aspettativa della self-information:
\begin{itemize}
    \item Per una variabile casuale discreta:
    \[
    H(X) = E_{X \sim P}[I(X)] = - \sum_{x \in \Omega} P(x) \log P(x)
    \]
    \item Per una variabile casuale continua:
    \[
    H(X) = E_{X \sim P}[I(X)] = - \int_{x \in \Omega} f(x) \log f(x) \, dx
    \]
\end{itemize}

\paragraph{Entropia di una variabile di Bernoulli}
Un esempio semplice è l'entropia di una variabile casuale di Bernoulli con parametro \(\phi\) (probabilità di successo):
\[
H(X) = - \left[ \phi \log \phi + (1 - \phi) \log (1 - \phi) \right]
\]

Si può notare che l'entropia è massima quando \(\phi = 0.5\) (massima incertezza) e minima quando \(\phi = 0\) o \(\phi = 1\) (nessuna incertezza), come si vede nell'immagine \ref{fig:bernoulli_entropy}.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.7\textwidth]{images/berrnoulli_entropy.png}
    \caption{Entropia \(H(X)\) di una variabile casuale di Bernoulli in funzione del parametro \(\phi\). L'entropia è massima a \(\phi = 0.5\) e minima a \(\phi = 0\) o \(\phi = 1\).}
    \label{fig:bernoulli_entropy}
\end{figure}

\subsection{Standardizzazione}
La standardizzazione è una tecnica utilizzata per trasformare una variabile casuale in modo che abbia media zero e deviazione standard uno. Questo processo è utile per confrontare variabili con scale diverse o per preparare i dati per algoritmi di machine learning che sono sensibili alla scala delle caratteristiche. La standardizzazione di una variabile casuale \(X\) con media \(\mu\) e deviazione standard \(\sigma\) è data dalla formula:
\[
Z = \frac{X - \mu_X}{\sigma_X} = \frac{X - E[X]}{\sqrt{Var[X]}}
\]

Dove \(Z\) è la variabile standardizzata. Dopo la standardizzazione, \(Z\) avrà una media di 0 e una deviazione standard di 1. Questa tecnica è anche chiamata z-scoring.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{images/standardizzazione.png}
    \caption{Effetto della standardizzazione su una variabile casuale. A sinistra: distribuzione originale della variabile (in blu), confrontata con una normale standard (media 0, deviazione standard 1) mostrata in verde tratteggiato: le scale sono diverse, quindi le curve non sono confrontabili direttamente. A destra: la stessa variabile dopo standardizzazione $Z = \frac{X - \mu_X}{\sigma_X}$; ora i dati trasformati hanno media 0 e deviazione standard 1 e risultano allineati alla distribuzione normale standard.}
    \label{fig:standardizzazione}
\end{figure}

Come si evince dalla figura \ref{fig:standardizzazione}, la standardizzazione consente di confrontare direttamente la distribuzione della variabile casuale con una distribuzione normale standard, facilitando l'analisi statistica.