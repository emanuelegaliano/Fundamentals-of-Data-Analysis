% Suggerimento: per rendere più gradevoli le citazioni, creiamo un ambiente dedicato.
% Puoi spostare la definizione nel preambolo se preferisci riutilizzarla in altri capitoli.

\chapter{Concetti chiave dell'analisi dei dati}

\section{Concetti fondamentali}

\subsection{Data}
\begin{nicequote}
    Un dato è un insieme di valori raccolti riguardanti un fenomeno, un evento o un'entità specifica. I dati possono essere numerici, testuali, visivi o di altro tipo e sono fondamentali per l'analisi statistica e il machine learning.
\end{nicequote}

\subsection{Popolazione}\label{subsec:popolazione}
\begin{nicequote}
    La popolazione è l'insieme completo di tutte le osservazioni o unità di interesse in uno studio statistico. Può essere costituita da persone, oggetti, eventi o qualsiasi altra entità che si desidera analizzare.
\end{nicequote}

La popolazione può essere denotata dal simbolo $\Omega$.

\subsection{Osservazioni}
\begin{nicequote}
    Un'osservazione è un'istanza specifica di dati raccolti su un'entità o un evento. In un dataset, ogni riga rappresenta un'osservazione, che include tutti i valori delle variabili misurate per quell'istanza.
\end{nicequote}

Dato un insieme popolazione $\Omega$, le osservazioni si indicheranno con:
\[
\omega \in \Omega
\]

\subsection{Campione}
\begin{nicequote}
    Un campione è un sottoinsieme rappresentativo della popolazione, selezionato per l'analisi statistica. I campioni sono utilizzati per fare inferenze sulla popolazione più ampia, poiché spesso è impraticabile o impossibile raccogliere dati su ogni membro della popolazione.
\end{nicequote}

Si parla di un campione come la tupla:
\[
\{\omega^{(1)}, \omega^{(2)}, ..., \omega^{(n)}\} \subseteq \Omega
\]
Dove ogni $\omega^{(i)}$ è un'osservazione appartenente alla popolazione $\Omega$ e $n$ è la dimensione del campione.
\subsection{Variabile}
\begin{nicequote}
    Una variabile, o feature, è una caratteristica misurabile o osservabile di un'osservazione. Quindi è una funzione che associa ad ogni osservazione un valore in un certo dominio.
\end{nicequote}

Definiamo la variabile $X$ come una funzione:
\[
X: \Omega \rightarrow S
\]

Dove $S$ è l'insieme dei possibili valori che la variabile può assumere. Quindi possiamo ridefinire l'osservazione come:
\[
\omega \rightarrow x
\]

Ovvero, l'osservazione $\omega$ viene mappata al valore $x$ tramite la variabile $X$. Esistono diverse tipologie di variabili:
\begin{itemize}
    \item \textbf{Quantitative:} assumono valori numerici e permettono operazioni aritmetiche.
    \item \textbf{Qualitative:} assumono valori categorici e non permettono operazioni aritmetiche.
    \item \textbf{Discrete:} assumono un numero finito o numerabile di valori.
    \item \textbf{Continue:} assumono un numero infinito di valori all'interno di un intervallo.
    \item \textbf{Scalare:} assumono un singolo valore per ogni osservazione.
    \item \textbf{Multi-dimensionali:} assumono più valori per ogni osservazione.
\end{itemize}

\subsection{Scale di misurazione}
\begin{nicequote}
    Le scale di misurazione sono sistemi utilizzati per classificare e quantificare le variabili in base alle loro caratteristiche.
\end{nicequote}

\noindent
Esistono diverse scale di misurazione:
\begin{itemize}
    \item \textbf{Nominale:} classifica le osservazioni in categorie senza un ordine specifico.
    \item \textbf{Ordinale:} classifica le osservazioni in categorie con un ordine specifico, ma senza una distanza definita tra le categorie.
    \item \textbf{Intervallo:} misura le differenze tra le osservazioni, ma non ha un punto zero assoluto.
    \item \textbf{Ratio:} misura le differenze tra le osservazioni e ha un punto zero assoluto.
\end{itemize}

\section{Organizzazione dei dati}

\subsection{Datasets}
\begin{nicequote}
    Un dataset è una raccolta strutturata di dati organizzati in righe e colonne, dove ogni riga rappresenta un'osservazione e ogni colonna rappresenta una variabile.
\end{nicequote}

\subsection{Design matrix}\label{sec:design_matrix}
\begin{nicequote}
    Una design matrix è una rappresentazione tabellare dei dati in cui le righe corrispondono alle osservazioni e le colonne corrispondono alle variabili (o feature).
\end{nicequote}

\noindent
Da questo possiamo notare che:
\begin{itemize}
    \item Le Osservazioni sono rappresentate dalle righe del dataset.
    \item Le Variabili (o feature) sono rappresentate dalle colonne del dataset, catturate grazie alle osservazioni.
    \item I campioni e la popolazione, nel dataset, possono essere visti come una sottotabella del completo.
\end{itemize}

\paragraph{Valori nulli.}
In alcuni casi, i dati raccolti possono essere incompleti, con alcune osservazioni che mancano di valori per determinate variabili. Questi valori mancanti sono spesso indicati come "NA" (Not Available) o "null". Potrebbe essere dato da un errore durante la raccolta dati, ma in generale la gestione dei dati mancanti è importante nell'analisi dei dati, poiché può influenzare i risultati delle analisi statistiche e/o dei modelli di machine learning.

\paragraph{Outlier.} 
In un dataset, un outlier è un'osservazione che si discosta significativamente dalle altre osservazioni, un valore "fuori scala". Gli outlier possono essere il risultato di errori di misurazione, errori di inserimento dati o possono rappresentare fenomeni rari ma validi.

\section{Collezione dei dati}
I dati possono essere ottenuti attraverso diverse fonti e metodi. Si parla del primo step per procedere all'analisi dei dati, in quanto la qualità e la rilevanza dei dati raccolti influenzano direttamente i risultati dell'analisi.

\subsection{Surveys}
\begin{nicequote}
    I surveys sono strumenti di raccolta dati che consistono in questionari o interviste progettati per ottenere informazioni specifiche da un gruppo di persone.
\end{nicequote}

I surveys possono essere somministrati in vari modi, tra cui questionari cartacei, interviste telefoniche, sondaggi online o interviste faccia a faccia. La progettazione di un survey efficace richiede attenzione alla formulazione delle domande, alla selezione del campione e alla modalità di somministrazione per garantire la raccolta di dati accurati e rappresentativi.

Il problema dei survey è che spesso le risposte possono essere influenzate da bias (come il bias di desiderabilità sociale, dove i partecipanti rispondono in modo da apparire più favorevoli agli occhi degli altri, piuttosto che fornire risposte oneste), ma in generale non si parla di dati \emph{altamente affidabili}.

\subsection{Esperimenti}
\begin{nicequote}
    Gli esperimenti sono studi controllati in cui i ricercatori manipolano una o più variabili indipendenti per osservare l'effetto su una o più variabili dipendenti.
\end{nicequote}

Gli esperimenti possono essere condotti in laboratorio o sul campo e richiedono un'attenta progettazione per garantire che i risultati siano validi e affidabili. Gli esperimenti spesso includono gruppi di controllo e randomizzazione per minimizzare i bias e isolare gli effetti delle variabili manipolate.

Uno dei tipi di esperimenti più comuni è la tipologia RCT (Randomized Controlled Trial), in cui i partecipanti sono assegnati casualmente a gruppi sperimentali o di controllo.

Gli esperimenti hanno un difetto: sono costosi e richiedono tempo per essere condotti, ma in generale si parla di dati \emph{molto affidabili}.

\subsection{Dati osservabili}
\begin{nicequote}
    I dati osservabili sono dati raccolti attraverso l'osservazione diretta di fenomeni, eventi o comportamenti senza manipolazione o intervento da parte del ricercatore.
\end{nicequote}

Questi eventi sono utili quando gli esperimenti sono impraticabili, non etici oppure vanno fuori budget.

I dati osservabili hanno un difetto: possono essere influenzati da fattori esterni non controllati, ma in generale si parla di dati \emph{affidabili}.

\subsection*{Fonti online}
Nella data science moderna, una fonte sempre più comune di dati è rappresentata dalle fonti online. Questi dati possono essere raccolti da siti web, social media, database pubblici e altre piattaforme digitali.

\section{Data Wrangling}
\begin{nicequote}
    Il data wrangling, o data munging, è il processo di pulizia, trasformazione e organizzazione dei dati grezzi in un formato utilizzabile per l'analisi.
\end{nicequote}

Come dicevamo nella sezione \ref{sec:design_matrix}, i dati grezzi non sono mai perfettamente puliti: spesso contengono errori, valori mancanti, outlier e formati incoerenti che devono essere affrontati prima di procedere con l'analisi.

\subsection{Gestire i valori nulli o mancanti}
I valori nulli o mancanti possono essere gestiti in diversi modi, tra cui:
\begin{itemize}
    \item Rimozione delle osservazioni con valori mancanti.
    \item Imputazione dei valori mancanti utilizzando la media, la mediana o la moda delle altre osservazioni.
    \item Utilizzo di modelli predittivi per stimare i valori mancanti basati su altre variabili.
\end{itemize}

\subsection{Conversione dei dati}
Alcune volte i dati vengono raccolti male, allora è necessario convertirli in formati più utili per l'analisi. 

\subsection{Rinominazione e riformattazione dei dati}
Rinominare e formattare i dati in modo coerente può facilitare l'analisi e la comprensione del dataset.

\subsection{Creazione di nuove feature}
A volte è utile creare nuove feature basate su quelle esistenti per migliorare l'analisi.

\subsection{Filtraggio e selezione dei dati}
Filtrare e selezionare i dati rilevanti per l'analisi può migliorare l'efficienza e la precisione dei risultati. 

\section{Formato dei dati}
I dati possono essere organizzati in formati differenti in base alle esisgenze dell'analisi.

\subsection{Formato largo}
Quando si parla di formato largo (wide format), i dati sono organizzati in modo tale che:
\begin{itemize}
    \item Ogni variabile è rappresentata da una colonna separata.
    \item Ogni osservazione è rappresentata da una riga separata.
\end{itemize}

I vantaggi sono la facile lettura e la struttura intuitiva, ma può essere inefficiente per dataset con molte variabili o osservazioni. Si usa infatti, nell'analisi esplorativa dei dati e nella visualizzazione.

\subsection{Formato lungo}
Nel caso del formato lungo (long format), i dati sono organizzati in modo tale che:
\begin{itemize}
    \item Le variabili sono rappresentate in una colonna separata.
    \item Le osservazioni sono rappresentate in più righe, con ogni riga che rappresenta una combinazione di osservazione e variabile.
\end{itemize}
I vantaggi sono l'efficienza nella memorizzazione e la facilità di manipolazione dei dati, ma può essere più difficile da leggere e interpretare. Si usa infatti, spesso nei modelli statistici e nelle analisi di serie temporali.

\subsection{Altre tecniche di Wrangling}
Esistono altre tecniche di data wrangling che possono essere utilizzate per preparare i dati per l'analisi, tra cui:
\begin{itemize}
    \item Conversione dell'unità di misura
    \item Normalizzazione dei valori
    \item Aggregazione dei dati
    \item Riduzione della dimensionalità
    \item Rimuovere duplicati
    \item Estrarre informazione e parsing di stringhe
    \item Ricampionamento dei dati tra formati lunghi e larghi.
\end{itemize}

\section{Il flusso di lavoro dell'Analisi dei dati}
La definizione che viene data, all'analisi dei dati, è:
\begin{nicequote}
    L'analisi dei dati è il processo di ispezione, pulizia, trasformazione e modellazione dei dati con l'obiettivo di scoprire informazioni utili, trarre conclusioni e supportare il processo decisionale.
\end{nicequote}

\subsection{Passaggi fondamentali}
Il flusso di lavoro tipico per l'analisi dei dati include i seguenti passaggi fondamentali:
\begin{description}
    \item[Ispezione o Data exploration: ] Esplorare i dati per comprendere la loro struttura, qualità e caratteristiche principali. 
    \item[Pulizia dei dati: ] Rimuovere o correggere errori, valori mancanti e outlier nei dati.
    \item[Trasformazione dei dati: ] Modificare i dati per renderli più adatti all'analisi, ad esempio creando nuove feature o convertendo i dati in formati diversi.
    \item[Modellazione dei dati: ] Applicare tecniche statistiche o di machine learning per analizzare i dati e trarre conclusioni.
\end{description}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.7\textwidth]{images/workflow.png}
    \caption{Flusso di lavoro dell'analisi dei dati.}
    \label{fig:data_analysis_workflow}
\end{figure}

Generalmente esiste un workflow iterativo e, ormai, standardizzato per l'analisi dei dati, che può essere riassunto nei seguenti passaggi:
\begin{enumerate}
    \item Definire l'obiettivo dell'analisi.
    \item Raccogliere i dati rilevanti.
    \item Pulire e preparare i dati. Gestire i valori mancanti, rimuovere outlier, creare nuove feature, ecc.
    \item Esplorare i dati. Utilizzare tecniche di visualizzazione e statistiche descrittive per comprendere la distribuzione dei dati, identificare pattern interessanti e relazioni tra le variabili.
    \item Model lifecycle. Applicare un modello statistico o di machine learning per analizzare i dati.
    \item Revisionare e aggiornare l'analisi. Basandosi sui risultati ottenuti, si potrebbe rivedere l'analisi, apportare modifiche ai dati o al modello e ripetere il processo se necessario.
\end{enumerate}

Sebbene questo sembri un modello molto lineare e sequenziale, spesso non lo è. Infatti, si può rappresentare il flusso di lavoro dell'analisi dei dati come un ciclo iterativo, in cui si torna indietro a fasi precedenti in base ai risultati ottenuti e alle nuove informazioni scoperte durante l'analisi (come si vede in figura \ref{fig:data_analysis_workflow}).
