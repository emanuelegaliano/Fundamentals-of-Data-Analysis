\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Distribuzione dei dati}{37}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Distribuzione di probabilità}{37}{section.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Distribuzioni discrete}{37}{section.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Funzione di massa di probabilità (PMF)}{37}{subsection.5.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Funzione di distribuzione cumulativa (CDF)}{38}{subsection.5.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Distribuzioni continue}{38}{section.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}Funzione di densità di probabilità (PDF)}{38}{subsection.5.3.1}\protected@file@percent }
\newlabel{subsec:pdf}{{5.3.1}{38}{Funzione di densità di probabilità (PDF)}{subsection.5.3.1}{}}
\@writefile{toc}{\contentsline {paragraph}{PDF uniforme.}{39}{section*.14}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Esempio di PDF uniforme continua su un intervallo $[a, b]$. La funzione è costante all'interno dell'intervallo e zero al di fuori.}}{39}{figure.5.1}\protected@file@percent }
\newlabel{fig:uniform_pdf}{{5.1}{39}{Esempio di PDF uniforme continua su un intervallo $[a, b]$. La funzione è costante all'interno dell'intervallo e zero al di fuori}{figure.5.1}{}}
\@writefile{toc}{\contentsline {paragraph}{Approssimare la PDF con istogrammi.}{39}{section*.15}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Confronto tra due rappresentazioni dell'istogramma delle età dei passeggeri. A sinistra: istogramma normalizzato, in cui l'altezza di ciascun bin è pari alla frequenza relativa (la somma delle altezze dei bin è 1); l'asse $y$ è interpretato come probabilità. A destra: istogramma di densità, in cui l'area totale sotto le barre è 1 e quindi le altezze approssimano la funzione di densità di probabilità continua. In rosso è mostrata la PDF normale stimata sui dati.}}{40}{figure.5.2}\protected@file@percent }
\newlabel{fig:histogram_pdf_comparison}{{5.2}{40}{Confronto tra due rappresentazioni dell'istogramma delle età dei passeggeri. A sinistra: istogramma normalizzato, in cui l'altezza di ciascun bin è pari alla frequenza relativa (la somma delle altezze dei bin è 1); l'asse $y$ è interpretato come probabilità. A destra: istogramma di densità, in cui l'area totale sotto le barre è 1 e quindi le altezze approssimano la funzione di densità di probabilità continua. In rosso è mostrata la PDF normale stimata sui dati}{figure.5.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}Funzione di distribuzione cumulativa (CDF)}{41}{subsection.5.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Distribuzioni di probabilità comuni}{41}{section.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.1}Distribuzione uniforme discreta}{41}{subsection.5.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.2}Distribuzione di Bernoulli}{41}{subsection.5.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Esempio di distribuzione di Bernoulli su una moneta truccata con parametro $\phi = 0.6$. La probabilità di successo (ovvero fare testa) è 0.6, mentre la probabilità di fallimento (fare croce) è 0.4}}{42}{figure.5.3}\protected@file@percent }
\newlabel{fig:bernoulli_distribution}{{5.3}{42}{Esempio di distribuzione di Bernoulli su una moneta truccata con parametro $\phi = 0.6$. La probabilità di successo (ovvero fare testa) è 0.6, mentre la probabilità di fallimento (fare croce) è 0.4}{figure.5.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.3}Distribuzione binomiale}{42}{subsection.5.4.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Funzioni di massa di probabilità (PMF) della distribuzione binomiale per diversi valori di $n$ (numero di prove) e $p$ (probabilità di successo in ciascuna prova). Ogni curva mostra la probabilità di ottenere $k$ successi su $n$ prove indipendenti: si osserva che il picco della distribuzione si sposta attorno al valore atteso $np$ e che, al crescere di $n$, la distribuzione tende a diventare più concentrata e più simile a una forma "gaussiana".}}{43}{figure.5.4}\protected@file@percent }
\newlabel{fig:binomial_distribution}{{5.4}{43}{Funzioni di massa di probabilità (PMF) della distribuzione binomiale per diversi valori di $n$ (numero di prove) e $p$ (probabilità di successo in ciascuna prova). Ogni curva mostra la probabilità di ottenere $k$ successi su $n$ prove indipendenti: si osserva che il picco della distribuzione si sposta attorno al valore atteso $np$ e che, al crescere di $n$, la distribuzione tende a diventare più concentrata e più simile a una forma "gaussiana"}{figure.5.4}{}}
\@writefile{toc}{\contentsline {paragraph}{Lancio di una moneta.}{43}{section*.16}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.4}Distribuzione categorica}{43}{subsection.5.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Esempio: lancio di un dado truccato.}{44}{section*.17}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces Esempio di distribuzione categorica per il lancio di un dado truccato. Le altezze delle barre rappresentano le probabilità associate a ciascuna faccia del dado.}}{44}{figure.5.5}\protected@file@percent }
\newlabel{fig:categorical_distribution}{{5.5}{44}{Esempio di distribuzione categorica per il lancio di un dado truccato. Le altezze delle barre rappresentano le probabilità associate a ciascuna faccia del dado}{figure.5.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.5}Distribuzione multinomiale}{45}{subsection.5.4.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Lancio di un dado più volte.}{45}{section*.18}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces Esempio di distribuzione multinomiale per il lancio di un dado a sei facce 15 volte. Le altezze delle barre rappresentano le probabilità associate a ciascuna combinazione di occorrenze delle facce del dado.}}{46}{figure.5.6}\protected@file@percent }
\newlabel{fig:multinomial_distribution}{{5.6}{46}{Esempio di distribuzione multinomiale per il lancio di un dado a sei facce 15 volte. Le altezze delle barre rappresentano le probabilità associate a ciascuna combinazione di occorrenze delle facce del dado}{figure.5.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.6}Distribuzione Gaussiana (Normale)}{46}{subsection.5.4.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.7}{\ignorespaces Esempio di distribuzione Gaussiana (Normale) con media \(\mu = 0\) e deviazione standard \(\sigma = 1\). La curva a campana rappresenta la funzione di densità di probabilità (PDF) della distribuzione.}}{46}{figure.5.7}\protected@file@percent }
\newlabel{fig:gaussian_distribution}{{5.7}{46}{Esempio di distribuzione Gaussiana (Normale) con media \(\mu = 0\) e deviazione standard \(\sigma = 1\). La curva a campana rappresenta la funzione di densità di probabilità (PDF) della distribuzione}{figure.5.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.7}Teorema del limite centrale}{48}{subsection.5.4.7}\protected@file@percent }
\newlabel{sec:clt}{{5.4.7}{48}{Teorema del limite centrale}{subsection.5.4.7}{}}
\newlabel{quote:clt}{{5.2}{48}{Teorema del limite centrale}{nicequotecnt.5.2}{}}
\@writefile{toc}{\contentsline {paragraph}{Esempio.}{48}{section*.19}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.8}{\ignorespaces Esempio del teorema del limite centrale con il lancio di un dado equo. La distribuzione delle medie campionarie tende a una distribuzione normale.}}{48}{figure.5.8}\protected@file@percent }
\newlabel{fig:central_limit_theorem}{{5.8}{48}{Esempio del teorema del limite centrale con il lancio di un dado equo. La distribuzione delle medie campionarie tende a una distribuzione normale}{figure.5.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.8}Distribuzione Gaussiana Multivariata}{49}{subsection.5.4.8}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.9}{\ignorespaces Distribuzione Gaussiana bivariata con media \((0,0)\). La superficie 3D mostra la densità congiunta, mentre le curve di livello (ellissi) mostrano linee di uguale densità sul piano $XY$. L'orientamento delle ellissi è determinato dalla matrice di covarianza $\Sigma $.}}{49}{figure.5.9}\protected@file@percent }
\newlabel{fig:multivariate_gaussian}{{5.9}{49}{Distribuzione Gaussiana bivariata con media \((0,0)\). La superficie 3D mostra la densità congiunta, mentre le curve di livello (ellissi) mostrano linee di uguale densità sul piano $XY$. L'orientamento delle ellissi è determinato dalla matrice di covarianza $\Sigma $}{figure.5.9}{}}
\@writefile{toc}{\contentsline {paragraph}{Effetti di $\Sigma $.}{49}{section*.20}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.10}{\ignorespaces Effetto della matrice di covarianza $\Sigma $ sulla distribuzione Gaussiana bivariata con media \((0,0)\). Ogni pannello mostra le curve di livello (isodensità), che evidenziano forma, orientamento e scala della distribuzione. Nella riga superiore: caso isotropico (varianze uguali su $X$ e $Y$), poi varianza di $X$ maggiore di quella di $Y$, poi varianza di $Y$ maggiore di quella di $X$; in questi casi $\Sigma $ è diagonale, quindi non c'è covarianza e le ellissi sono allineate con gli assi. Nella riga inferiore: presenza di termini fuori diagonale in $\Sigma $ (covarianza non nulla), che introduce correlazione tra le variabili. Con correlazione positiva le ellissi ruotano lungo la diagonale crescente, con correlazione negativa lungo la diagonale decrescente. Questo mostra che $\Sigma $ controlla non solo quanto è larga la distribuzione in ciascuna direzione, ma anche come è orientata nello spazio.}}{50}{figure.5.10}\protected@file@percent }
\newlabel{fig:multivariate_sigma_effects}{{5.10}{50}{Effetto della matrice di covarianza $\Sigma $ sulla distribuzione Gaussiana bivariata con media \((0,0)\). Ogni pannello mostra le curve di livello (isodensità), che evidenziano forma, orientamento e scala della distribuzione. Nella riga superiore: caso isotropico (varianze uguali su $X$ e $Y$), poi varianza di $X$ maggiore di quella di $Y$, poi varianza di $Y$ maggiore di quella di $X$; in questi casi $\Sigma $ è diagonale, quindi non c'è covarianza e le ellissi sono allineate con gli assi. Nella riga inferiore: presenza di termini fuori diagonale in $\Sigma $ (covarianza non nulla), che introduce correlazione tra le variabili. Con correlazione positiva le ellissi ruotano lungo la diagonale crescente, con correlazione negativa lungo la diagonale decrescente. Questo mostra che $\Sigma $ controlla non solo quanto è larga la distribuzione in ciascuna direzione, ma anche come è orientata nello spazio}{figure.5.10}{}}
\@writefile{toc}{\contentsline {paragraph}{Stime dei parametri nella distribuzione Gaussiana multivariata.}{51}{section*.21}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Descrivere una distribuzione di probabilità}{51}{section.5.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.1}Aspettativa (media)}{51}{subsection.5.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.2}Varianza e deviazione standard}{52}{subsection.5.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.3}Covarianza}{52}{subsection.5.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.4}Entropia}{53}{subsection.5.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Self-information.}{53}{section*.22}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.11}{\ignorespaces Esempio di self-information \(I(x) = -\log P(x)\) per diversi valori di probabilità \(P(x)\). Si nota che eventi con bassa probabilità (vicino a 0) hanno alta self-information, mentre eventi con alta probabilità (vicino a 1) hanno bassa self-information.}}{53}{figure.5.11}\protected@file@percent }
\newlabel{fig:self_information}{{5.11}{53}{Esempio di self-information \(I(x) = -\log P(x)\) per diversi valori di probabilità \(P(x)\). Si nota che eventi con bassa probabilità (vicino a 0) hanno alta self-information, mentre eventi con alta probabilità (vicino a 1) hanno bassa self-information}{figure.5.11}{}}
\@writefile{toc}{\contentsline {paragraph}{Entropia di una distribuzione.}{54}{section*.23}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Entropia di una variabile di Bernoulli}{54}{section*.24}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.12}{\ignorespaces Entropia \(H(X)\) di una variabile casuale di Bernoulli in funzione del parametro \(\phi \). L'entropia è massima a \(\phi = 0.5\) e minima a \(\phi = 0\) o \(\phi = 1\).}}{54}{figure.5.12}\protected@file@percent }
\newlabel{fig:bernoulli_entropy}{{5.12}{54}{Entropia \(H(X)\) di una variabile casuale di Bernoulli in funzione del parametro \(\phi \). L'entropia è massima a \(\phi = 0.5\) e minima a \(\phi = 0\) o \(\phi = 1\)}{figure.5.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.5}Standardizzazione}{54}{subsection.5.5.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.13}{\ignorespaces Effetto della standardizzazione su una variabile casuale. A sinistra: distribuzione originale della variabile (in blu), confrontata con una normale standard (media 0, deviazione standard 1) mostrata in verde tratteggiato: le scale sono diverse, quindi le curve non sono confrontabili direttamente. A destra: la stessa variabile dopo standardizzazione $Z = \frac  {X - \mu _X}{\sigma _X}$; ora i dati trasformati hanno media 0 e deviazione standard 1 e risultano allineati alla distribuzione normale standard.}}{55}{figure.5.13}\protected@file@percent }
\newlabel{fig:standardizzazione}{{5.13}{55}{Effetto della standardizzazione su una variabile casuale. A sinistra: distribuzione originale della variabile (in blu), confrontata con una normale standard (media 0, deviazione standard 1) mostrata in verde tratteggiato: le scale sono diverse, quindi le curve non sono confrontabili direttamente. A destra: la stessa variabile dopo standardizzazione $Z = \frac {X - \mu _X}{\sigma _X}$; ora i dati trasformati hanno media 0 e deviazione standard 1 e risultano allineati alla distribuzione normale standard}{figure.5.13}{}}
\@setckpt{data_distrb}{
\setcounter{page}{56}
\setcounter{equation}{0}
\setcounter{enumi}{2}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{3}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{5}
\setcounter{section}{5}
\setcounter{subsection}{5}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{13}
\setcounter{table}{0}
\setcounter{float@type}{16}
\setcounter{lstnumber}{1}
\setcounter{parentequation}{0}
\setcounter{section@level}{2}
\setcounter{Item}{8}
\setcounter{Hfootnote}{4}
\setcounter{bookmark@seq@number}{108}
\setcounter{tcbbreakpart}{1}
\setcounter{tcblayer}{0}
\setcounter{tcolorbox@number}{45}
\setcounter{tcbrastercolumn}{1}
\setcounter{tcbrasterrow}{1}
\setcounter{tcbrasternum}{1}
\setcounter{tcbraster}{0}
\setcounter{tcblisting}{0}
\setcounter{nicequotecnt}{2}
\setcounter{lstlisting}{0}
}
