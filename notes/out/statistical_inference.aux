\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Inferenza Statistica}{57}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Campionamento}{57}{section.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.1}Campionamento casuale semplice}{57}{subsection.6.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces Illustrazione del campionamento casuale semplice da una popolazione normale. Ogni riga corrisponde a un diverso numero di osservazioni campionate dalla stessa popolazione (\(n = 5, 20, 50, 100, 1000\)). Nella prima colonna è mostrata la distribuzione della popolazione (istogramma ad alta risoluzione con la sua densità teorica). Nella seconda colonna è mostrato l'istogramma del singolo campione estratto a quella dimensione \(n\), con una stima di densità sovrapposta. Nella terza colonna è mostrata la stima di densità (KDE, in rosso) del campione confrontata con la densità della popolazione reale (in blu). All'aumentare della dimensione del campione, l'istogramma e la densità stimata del campione diventano via via più simili alla distribuzione originale della popolazione: questo evidenzia che campioni più grandi approssimano meglio la popolazione.}}{58}{figure.6.1}\protected@file@percent }
\newlabel{fig:simple_random_sampling}{{6.1}{58}{Illustrazione del campionamento casuale semplice da una popolazione normale. Ogni riga corrisponde a un diverso numero di osservazioni campionate dalla stessa popolazione (\(n = 5, 20, 50, 100, 1000\)). Nella prima colonna è mostrata la distribuzione della popolazione (istogramma ad alta risoluzione con la sua densità teorica). Nella seconda colonna è mostrato l'istogramma del singolo campione estratto a quella dimensione \(n\), con una stima di densità sovrapposta. Nella terza colonna è mostrata la stima di densità (KDE, in rosso) del campione confrontata con la densità della popolazione reale (in blu). All'aumentare della dimensione del campione, l'istogramma e la densità stimata del campione diventano via via più simili alla distribuzione originale della popolazione: questo evidenzia che campioni più grandi approssimano meglio la popolazione}{figure.6.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.2}Campionamento stratificato}{58}{subsection.6.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces Confronto tra diversi metodi di campionamento su una popolazione suddivisa in 10 professioni. Riga superiore: popolazione completa, mostrata sia come dot plot (a sinistra, ogni punto è un individuo colorato per professione) sia come istogramma normalizzato (a destra, proporzioni reali di ciascuna professione nella popolazione). Riga centrale: campione ottenuto tramite campionamento casuale semplice (uniform random sample). Le proporzioni osservate nel campione possono discostarsi da quelle reali della popolazione, specialmente per le categorie meno frequenti. Riga inferiore: campione stratificato (stratified sample), in cui si forza la presenza di ogni categoria in proporzione alla popolazione. In questo caso, l'istogramma delle proporzioni nel campione è molto più fedele alla distribuzione originale.}}{59}{figure.6.2}\protected@file@percent }
\newlabel{fig:stratified_sampling}{{6.2}{59}{Confronto tra diversi metodi di campionamento su una popolazione suddivisa in 10 professioni. Riga superiore: popolazione completa, mostrata sia come dot plot (a sinistra, ogni punto è un individuo colorato per professione) sia come istogramma normalizzato (a destra, proporzioni reali di ciascuna professione nella popolazione). Riga centrale: campione ottenuto tramite campionamento casuale semplice (uniform random sample). Le proporzioni osservate nel campione possono discostarsi da quelle reali della popolazione, specialmente per le categorie meno frequenti. Riga inferiore: campione stratificato (stratified sample), in cui si forza la presenza di ogni categoria in proporzione alla popolazione. In questo caso, l'istogramma delle proporzioni nel campione è molto più fedele alla distribuzione originale}{figure.6.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Campionare la distribuzione della media}{59}{section.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.1}Errore standard}{61}{subsection.6.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.3}{\ignorespaces Distribuzione delle medie campionarie per diversi valori di $n$ (10, 100, 1000) ottenute simulando il campionamento ripetuto dalla stessa popolazione. Ogni pannello mostra l'istogramma delle medie dei campioni e una stima di densità sovrapposta. All'aumentare della dimensione del campione, la distribuzione delle medie diventa più stretta attorno al valore medio della popolazione e la deviazione standard della media campionaria (errore standard) diminuisce in accordo con $\mathrm  {Std}[\bar  {X}] = \sigma / \sqrt  {n}$.}}{61}{figure.6.3}\protected@file@percent }
\newlabel{fig:standard_error_vs_sample_size}{{6.3}{61}{Distribuzione delle medie campionarie per diversi valori di $n$ (10, 100, 1000) ottenute simulando il campionamento ripetuto dalla stessa popolazione. Ogni pannello mostra l'istogramma delle medie dei campioni e una stima di densità sovrapposta. All'aumentare della dimensione del campione, la distribuzione delle medie diventa più stretta attorno al valore medio della popolazione e la deviazione standard della media campionaria (errore standard) diminuisce in accordo con $\mathrm {Std}[\bar {X}] = \sigma / \sqrt {n}$}{figure.6.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.2}Distribuzione t-Student}{61}{subsection.6.2.2}\protected@file@percent }
\newlabel{subsec:student_t_distribution}{{6.2.2}{61}{Distribuzione t-Student}{subsection.6.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.4}{\ignorespaces Confronto tra la distribuzione $t$ di Student e la distribuzione normale standard. Ogni curva $t$ corrisponde a un diverso numero di gradi di libertà ($n = 1, 2, 5, 30$). Per valori piccoli di $n$ la distribuzione $t$ ha code più pesanti (maggiore probabilità di valori estremi) e un picco più basso rispetto alla Gaussiana. All'aumentare di $n$, la distribuzione $t$ si avvicina alla distribuzione normale standard, fino a diventare praticamente indistinguibile per $n$ grandi.}}{62}{figure.6.4}\protected@file@percent }
\newlabel{fig:t_distribution_vs_normal}{{6.4}{62}{Confronto tra la distribuzione $t$ di Student e la distribuzione normale standard. Ogni curva $t$ corrisponde a un diverso numero di gradi di libertà ($n = 1, 2, 5, 30$). Per valori piccoli di $n$ la distribuzione $t$ ha code più pesanti (maggiore probabilità di valori estremi) e un picco più basso rispetto alla Gaussiana. All'aumentare di $n$, la distribuzione $t$ si avvicina alla distribuzione normale standard, fino a diventare praticamente indistinguibile per $n$ grandi}{figure.6.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.3}Intervallo di confidenza}{62}{subsection.6.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.5}{\ignorespaces Visualizzazione dell'intervallo $\,[\mu - \sigma ,\, \mu + \sigma ]$ (barra orizzontale blu) e delle medie campionarie $\bar  {X}_1, \bar  {X}_2, \ldots  , \bar  {X}_9$ ottenute da campioni diversi. Per ciascun campione è mostrato il suo intervallo $\bar  {X}_i \pm \sigma $ (barra orizzontale). I punti verdi indicano le medie campionarie i cui intervalli contengono la media reale $\mu $, mentre i punti rossi indicano quelle che non la contengono. L'idea è che, ripetendo il campionamento, la maggior parte degli intervalli stimati copre il valore vero del parametro, ma non tutti.}}{63}{figure.6.5}\protected@file@percent }
\newlabel{fig:confidence_interval_68}{{6.5}{63}{Visualizzazione dell'intervallo $\,[\mu - \sigma ,\, \mu + \sigma ]$ (barra orizzontale blu) e delle medie campionarie $\bar {X}_1, \bar {X}_2, \ldots , \bar {X}_9$ ottenute da campioni diversi. Per ciascun campione è mostrato il suo intervallo $\bar {X}_i \pm \sigma $ (barra orizzontale). I punti verdi indicano le medie campionarie i cui intervalli contengono la media reale $\mu $, mentre i punti rossi indicano quelle che non la contengono. L'idea è che, ripetendo il campionamento, la maggior parte degli intervalli stimati copre il valore vero del parametro, ma non tutti}{figure.6.5}{}}
\@writefile{toc}{\contentsline {paragraph}{Generalizzazione per altri livelli di confidenza.}{64}{section*.25}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Livello di significatività.}{64}{section*.26}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.6}{\ignorespaces Interpretazione dell'intervallo di confidenza al 95\%. L'area verde rappresenta l'intervallo di confidenza $(1-\alpha )=95\%$, che corrisponde ai valori della media campionaria $\bar  {X}$ che, una volta stimati sul campione, ``catturano'' la vera media $\mu $. Le aree rosse nelle code (ciascuna di area $\alpha /2$) rappresentano i casi in cui l'intervallo stimato non contiene la media reale: la probabilità complessiva di errore è $\alpha = 0.05$. Le linee tratteggiate verdi indicano i limiti $\bar  {X} \pm 1.96 \cdot SE(\bar  {X})$, mentre la linea tratteggiata nera indica la vera media $\mu $.}}{64}{figure.6.6}\protected@file@percent }
\newlabel{fig:confidence_interval_95}{{6.6}{64}{Interpretazione dell'intervallo di confidenza al 95\%. L'area verde rappresenta l'intervallo di confidenza $(1-\alpha )=95\%$, che corrisponde ai valori della media campionaria $\bar {X}$ che, una volta stimati sul campione, ``catturano'' la vera media $\mu $. Le aree rosse nelle code (ciascuna di area $\alpha /2$) rappresentano i casi in cui l'intervallo stimato non contiene la media reale: la probabilità complessiva di errore è $\alpha = 0.05$. Le linee tratteggiate verdi indicano i limiti $\bar {X} \pm 1.96 \cdot SE(\bar {X})$, mentre la linea tratteggiata nera indica la vera media $\mu $}{figure.6.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Bootstrapping}{65}{section.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.4}Stimatori}{65}{section.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4.1}Stimatore del bias}{65}{subsection.6.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4.2}Stimatore della varianza}{66}{subsection.6.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Varianza distorta.}{66}{section*.27}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4.3}Varianza di uno stimatore}{66}{subsection.6.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4.4}Bias-Varianza Tradeoff}{66}{subsection.6.4.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.7}{\ignorespaces Illustrazione concettuale di bias e varianza con l'analogia del bersaglio. Ogni pannello dell’immagine mostra una serie di stime (punti blu) rispetto al valore vero (centro del bersaglio). Il modo in cui i punti si distribuiscono rispetto al centro riflette combinazioni diverse di bias (quanto siamo lontani dal valore vero) e varianza (quanto le stime sono stabili tra loro).}}{67}{figure.6.7}\protected@file@percent }
\newlabel{fig:bias_variance_tradeoff}{{6.7}{67}{Illustrazione concettuale di bias e varianza con l'analogia del bersaglio. Ogni pannello dell’immagine mostra una serie di stime (punti blu) rispetto al valore vero (centro del bersaglio). Il modo in cui i punti si distribuiscono rispetto al centro riflette combinazioni diverse di bias (quanto siamo lontani dal valore vero) e varianza (quanto le stime sono stabili tra loro)}{figure.6.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.5}Test statistici}{67}{section.6.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5.1}Test di ipotesi}{67}{subsection.6.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Esempio: una moneta è truccata?}{68}{section*.28}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.8}{\ignorespaces Esempio di test di ipotesi su una moneta. Le barre mostrano la probabilità di ottenere \(k\) teste su 10 lanci se la moneta fosse equa (\(H_0 : p = 0.5\)). Le barre rosse evidenziano gli esiti “estremi” (\(k \leq 1\) o \(k \geq 9\)) che contribuiscono al valore \(p\) in un test bilaterale. Nell’esperimento osserviamo 9 teste (linea tratteggiata): questo caso cade in zona estrema. Il valore \(p \approx 2.15\%\) è minore di \(\alpha = 5\%\), quindi rifiutiamo \(H_0\) e concludiamo che ci sono evidenze per dire che la moneta è truccata (\(H_a : p \neq  0.5\)).}}{69}{figure.6.8}\protected@file@percent }
\newlabel{fig:hypothesis_testing_coin}{{6.8}{69}{Esempio di test di ipotesi su una moneta. Le barre mostrano la probabilità di ottenere \(k\) teste su 10 lanci se la moneta fosse equa (\(H_0 : p = 0.5\)). Le barre rosse evidenziano gli esiti “estremi” (\(k \leq 1\) o \(k \geq 9\)) che contribuiscono al valore \(p\) in un test bilaterale. Nell’esperimento osserviamo 9 teste (linea tratteggiata): questo caso cade in zona estrema. Il valore \(p \approx 2.15\%\) è minore di \(\alpha = 5\%\), quindi rifiutiamo \(H_0\) e concludiamo che ci sono evidenze per dire che la moneta è truccata (\(H_a : p \neq 0.5\))}{figure.6.8}{}}
\@writefile{toc}{\contentsline {paragraph}{Tipi di errori nei test statistici.}{69}{section*.29}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {6.1}{\ignorespaces Tabella di contingenza per i test di ipotesi.}}{70}{table.6.1}\protected@file@percent }
\newlabel{tab:contingency_table}{{6.1}{70}{Tabella di contingenza per i test di ipotesi}{table.6.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5.2}T-test a un campione}{70}{subsection.6.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5.3}T-test a due campioni}{70}{subsection.6.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5.4}Test $\chi ^2$ per indipendenza}{70}{subsection.6.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5.5}Test $\chi ^2$ di bontà di adattamento}{70}{subsection.6.5.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5.6}Test di correlazione di Pearson}{71}{subsection.6.5.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5.7}Test di correlazione di Spearman}{71}{subsection.6.5.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.6}Valutare quando un campione è distribuito normalmente}{71}{section.6.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6.1}Grafici Q-Q}{71}{subsection.6.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6.2}Test di normalità di Shapiro-Wilk}{71}{subsection.6.6.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.9}{\ignorespaces Q-Q plot rispetto alla normale: più i punti seguono la linea rossa, più i dati possono essere considerati circa normali.}}{72}{figure.6.9}\protected@file@percent }
\newlabel{fig:qq_plot_normal}{{6.9}{72}{Q-Q plot rispetto alla normale: più i punti seguono la linea rossa, più i dati possono essere considerati circa normali}{figure.6.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.10}{\ignorespaces Relazione tra forma delle code e Q-Q plot. Code troppo leggere (\textit  {short tails}) piegano verso l'interno; code pesanti (\textit  {long tails}) si incurvano verso l'esterno; una coda destra lunga fa salire la parte destra del Q-Q plot sopra la linea; una coda sinistra lunga fa scendere la parte sinistra sotto la linea.}}{72}{figure.6.10}\protected@file@percent }
\newlabel{fig:qq_plot_guidelines}{{6.10}{72}{Relazione tra forma delle code e Q-Q plot. Code troppo leggere (\textit {short tails}) piegano verso l'interno; code pesanti (\textit {long tails}) si incurvano verso l'esterno; una coda destra lunga fa salire la parte destra del Q-Q plot sopra la linea; una coda sinistra lunga fa scendere la parte sinistra sotto la linea}{figure.6.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6.3}Test \(K^2\) di D'Agostino}{73}{subsection.6.6.3}\protected@file@percent }
\@setckpt{statistical_inference}{
\setcounter{page}{74}
\setcounter{equation}{0}
\setcounter{enumi}{5}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{2}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{6}
\setcounter{section}{6}
\setcounter{subsection}{3}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{10}
\setcounter{table}{1}
\setcounter{float@type}{16}
\setcounter{lstnumber}{1}
\setcounter{parentequation}{0}
\setcounter{section@level}{2}
\setcounter{Item}{13}
\setcounter{Hfootnote}{6}
\setcounter{bookmark@seq@number}{134}
\setcounter{tcbbreakpart}{1}
\setcounter{tcblayer}{0}
\setcounter{tcolorbox@number}{45}
\setcounter{tcbrastercolumn}{1}
\setcounter{tcbrasterrow}{1}
\setcounter{tcbrasternum}{1}
\setcounter{tcbraster}{0}
\setcounter{tcblisting}{0}
\setcounter{nicequotecnt}{0}
\setcounter{lstlisting}{0}
}
